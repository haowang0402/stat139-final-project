---
title: "Appendix part I: EDA"
output: pdf_document
---

\newcommand{\noin}{\noindent}    
\newcommand{\Var}{\text{Var}}    
\newcommand{\Cov}{\text{Cov}}  

# Introduction

## Brief recap about our proposal

The core question of this project is to identify the pricing model of Uber / Lyft rides, and get an intuition about how to get cheap rides in Boston. The main tools for such analysis is regression.

The dataset used across this project is [Uber and Lyft Dataset Boston, MA](https://www.kaggle.com/datasets/brllrb/uber-and-lyft-dataset-boston-ma). The predictors we selected and cared about for the regression analysis includes:

- Distance of the ride
- Weather condition, including a categorical variable for the weather, and other statistics like temperature, humidity, visibility, etc.
- Pick up / Destination location
- Ride type: Uber or Lyft; more specific information about the vehicle, like Lyft XL, UberX, etc.

The interesting question includes: is Uber cheaper than Lyft or vice versa? What's the pricing model between distance and price? Since the data is around seasonal holidays, do time and location affect the price?

## A preview of what did in this milestone

Specifically, we did the following things:

- Subsampled the original dataset to create a scale that is processible by R, and compared the distribution of predictor variables to confirm that the distributions won't be off the original ones.

- Created visualizations and analysis without modeling to explore how time, location and weather conditions affect the price, and preprocess them in a proper way for future modeling.

- Built several models to perform regression analysis, including linear, polynomial regression using only the distance, and linear regression with interaction terms between distance and ride type (Uber and Lyft). We used these models to analyze the pricing model and try to answer the first two questions.

## What we will do next

We will be focusing on building a predictive model that utilizes all of the predictor variables we cared about. After that, we will try to interpret them with visuals and formal tests, and we will also use cross validation and RMSE metric to properly evaluate the predictive capability of such models.

In the end, we will attempt to answer all the questions we proposed and provide the Bostonians a practical ride suggestion supported by data. 

# Data Explorations

## Downsample Distribution
Since the original dataset is too big to process in R, we downsample the dataset to a smaller dataset. However, we'd like to make sure the distribution of the smaller dataaset is similar to the original dataset.

![price_percentage](price_percentage.jpg){height=2in} ![distance_percentage](distance_percentage.jpg){height=2in} 
![source_percentage](source_percentage.jpg){height=2in} 
![dest_percentage](dest_percentage.jpg){height=2in} 
![cab_type_percentage](cab_type_percentage.jpg){height=2in} 
![hour_percentage](hour_percentage.jpg){height=2in} 


It seems that the downsampling distribution is pretty similar to the original one besides the price distribution, which is a little bit off. We might want to adjust this in the future. 



## Evaluation of number of orders within the same range

It's intuitive for Uber/Lyft to use supply and demand to price the rides. Therefore, the price of the rides might be much higher if there are a lot of demands. We did some data preprocessing in python by calculating the number of rides within certain time intervals (15 mins here). If there are a lot of rides in the same time range, we expect the price of the rides will be higher. 

```{r, eval = T}
# read the data
rideshare = read.csv("data/sampled_rideshare.csv")
slide_window_df = read.csv("./data/rides_slide_window.csv")
hist(slide_window_df$number_of_orders_within_15_mins)
```

Based on the histogram, it seems that the number of rides is not very continuous. However, we could certainly see that there are certain time ranges (peak hours) with a lot of more rides. Since the value is not very continuous, it might be helpful to convert them into categorical variables based on some time ranges or use a decision tree model in the future. 

```{r, eval = T}
rideshare$busy = as.factor(
    ifelse(rideshare$number_of_orders_within_15_mins < 500, 
            "not busy", 
            ifelse(rideshare$number_of_orders_within_15_mins < 1000, 
            "normal", 
            "busy")))
```

```{r, eval = T}
boxplot(rideshare$price ~ rideshare$busy)
```
```{r, eval = T}
summary(aov(rideshare$price ~ rideshare$busy))
```
Based on the boxplot and the anova result, there is no significant difference between the price and the number of orders in the same time range. This is counter-intuitive. It might due to the data generation process. The data provider might presample some data to make each hour contains similar amount of orders. Since it does not represent the true distribution, then our calculation might be misleaded. 

```{r, eval = T}
hist(rideshare$hour)
```


## Preprocessing of data: Categorical or Numerical

### 1 MonthDayHour

Since the data comes solely from the span of two months, it makes sense to simply use the first day of Nov. as the baseline and the days as numerical in the range [1,61] and simply ignore the month column.

```{r cars}
n_sample = dim(rideshare)
for(i in 1:50000){
  if(rideshare[i,"month"] == "12"){
    rideshare[i,"day"] = rideshare[i,"day"] + 30
  }
}
```

For the hours columns, it makes sense to create another categorical variable that divides the hours into different periods of the day

```{r}
tmp = rep(0,50000)
for(i in 1:50000){
  if((rideshare[i,"hour"] > 6) && (rideshare[i,"hour"] <= 12)){
    tmp[i]="morning"
  }
  if((rideshare[i,"hour"] > 12) && (rideshare[i,"hour"] <= 18)){
    tmp[i]="afternoon"
  }
  if((rideshare[i,"hour"] > 18) && (rideshare[i,"hour"] <= 23)){
    tmp[i]="evening"
  }
  if((rideshare[i,"hour"] >= 0) && (rideshare[i,"hour"] <= 6)){
    tmp[i]="midnight"
  }
}
rideshare$period_of_day = tmp
barplot(prop.table(table(rideshare$period_of_day)))
library("ggpubr")
ggboxplot(rideshare, x = "period_of_day", y = "price", 
          color = "period_of_day",
        ylab = "price", xlab = "period_of_day")
```

And we see from the plot that the proportion is close to being even among the categories, which also justifies our categorization choice.

```{r}
morning_data = na.omit(rideshare$price[(rideshare$period_of_day == "morning")])
afternoon_data = na.omit(rideshare$price[(rideshare$period_of_day == "afternoon")])
evening_data = na.omit(rideshare$price[(rideshare$period_of_day == "evening")])
midnight_data = na.omit(rideshare$price[(rideshare$period_of_day == "midnight")])
mean_morning = mean(na.omit(rideshare$price[(rideshare$period_of_day == "morning")]))
mean_afternoon = mean(na.omit(rideshare$price[(rideshare$period_of_day == "afternoon")]))
mean_evening = mean(na.omit(rideshare$price[(rideshare$period_of_day == "evening")]))
mean_midnight = mean(na.omit(rideshare$price[(rideshare$period_of_day == "midnight")]))

mean_df = data.frame(morning = mean_morning,
                     afternoon = mean_afternoon,
                     evening = mean_evening,
                     midnight = mean_midnight)

# Pairwise t-test for the means
t.test(morning_data, afternoon_data)
t.test(morning_data, evening_data)
t.test(morning_data, midnight_data)
t.test(afternoon_data, evening_data)
t.test(afternoon_data, midnight_data)
t.test(evening_data, midnight_data)
res.ftest <- aov(price ~ period_of_day, data = rideshare)
```

```{r, eval = T}
res.ftest
```




